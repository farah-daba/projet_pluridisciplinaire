{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTIE QUESTIONS DETAILLEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger la cl√© depuis le fichier .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "# Pr√©parer la requ√™te\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ R√©ponse :\n",
      "‚ùå Erreur lors de l'appel √† Mistral :\n",
      "'choices'\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"mistral-tiny\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Dis bonjour en fran√ßais\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "# Envoi de la requ√™te\n",
    "try:\n",
    "    response = httpx.post(url, headers=headers, data=json.dumps(payload), timeout=15)\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ R√©ponse :\")\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Erreur lors de l'appel √† Mistral :\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚úàÔ∏è G√©n√©ration de ta recommandation..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Recommandation g√©n√©r√©e :"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Destination recommand√©e : Costa del Sol en Espagne. Elle offre des plages magnifiques et une ambiance agr√©able en √©t√©. Son climat est sec et ensoleill√©, id√©al pour les randonn√©es.\n",
       "\n",
       "Itin√©raire :\n",
       "1. Jour 1 : Arriv√©e √† M√°laga et installation √† l'h√¥tel.\n",
       "2. Jour 2-3 : Randonn√©es au Parc National de Sierra Nevada, o√π vous trouverez des sentiers adapt√©s √† tous les niveaux.\n",
       "3. Jour 4-5 : Visite de la ville de Marbella, avec ses plages et son centre-ville pittoresque. Une excursion √† la R√©serve naturelle de La Reserva del Ojen serait un excellent compl√©ment.\n",
       "4. Jour 6 : Jour de repos sur la plage de Benalmadena ou un bateau-mouche vers Puerto Ban√∫s pour la croisi√®re et la visite du port.\n",
       "5. Jour 7 : Sortie vers la R√©serve de la Sierra de las Nieves, un espace naturel prot√©g√© abritant des esp√®ces rares.\n",
       "6. Jour 8 : Depart et retour √† M√°laga pour le retour.\n",
       "\n",
       "Activit√©s principales :\n",
       "1. Randonn√©es dans les parcs naturels de Sierra Nevada et Sierra de las Nieves.\n",
       "2. Visite de la ville de Marbella et de sa plage.\n",
       "3. Excursion en bateau-mouche vers Puerto Ban√∫s.\n",
       "\n",
       "Suggestions d'h√©bergement :\n",
       "- Premium : H√¥tel Vincci Selecci√≥n Posada del Patio, M√°laga. Situ√© dans le centre-ville, cet h√¥tel offre des chambres spacieuses et confortables, une piscine et un restaurant gastronomique.\n",
       "- Budget : H√¥tel Bah√≠a Real Torrequebrada, Benalmadena. Offrant une belle vue sur la mer, cet h√¥tel est √©quip√© de piscine, restaurant, bar et un centre de wellness.\n",
       "\n",
       "Justification : La Costa del Sol est une destination populaire pour les couples qui aiment les plages et l'agreed'espace. Elle offre des opportunit√©s de randonn√©es dans des parcs naturels adjacents, ce qui r√©pond √† l'int√©r√™t de ceux qui aiment la randonn√©e. L'h√©bergement choisi est adapt√© aux go√ªts du couple et offre des services comme la piscine, le restaurant et le centre de wellness.\n",
       "\n",
       "Options alternatives (budget/premium) :\n",
       "- Pour un budget plus restreint, l'h√¥tel Iberostar M√°laga Playa est une option de qualit√©/prix int√©ressante.\n",
       "- Pour un choix de luxe, le Finca Cortes√≠n, situ√© √† Casares entre Marbella et Sotogrande, offre un niveau d'h√©bergement exceptionnel.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üí¨ Tu peux continuer la discussion :"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5759cf9ac4544b819e471472408ca5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dfeeb9ebb142259401e110c59a545d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='60px', width='100%'), placeholder='Pose une autre question, ou r√©agis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c19b1bd89c84efb8ca66bd377e78c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Envoyer üí¨', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# Charger la cl√© API\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Historique pour conversation continue\n",
    "historique_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant de voyage expert.\"}\n",
    "]\n",
    "\n",
    "# UI formulaire initial\n",
    "display(Markdown(\"### üëã Bienvenue dans l'assistant de voyage intelligent !\"))\n",
    "display(Markdown(\"Je vais te poser quelques questions pour mieux cerner tes envies de voyage üåç\"))\n",
    "\n",
    "# Widgets initiaux\n",
    "destination = widgets.Text(placeholder=\"ex : plage, montagne, ville...\", description=\"\")\n",
    "budget = widgets.Text(placeholder=\"ex : faible, 500‚Ç¨, moyen...\", description=\"\")\n",
    "dates = widgets.Text(placeholder=\"ex : du 15 au 22 juillet\", description=\"\")\n",
    "interets = widgets.Text(placeholder=\"ex : randonn√©e, mus√©es, gastronomie...\", description=\"\")\n",
    "hebergement = widgets.Text(placeholder=\"ex : h√¥tel, auberge, logement insolite...\", description=\"\")\n",
    "compagnie = widgets.Text(placeholder=\"ex : seul, en couple, en famille...\", description=\"\")\n",
    "contraintes = widgets.Text(placeholder=\"ex : animaux, enfants, mobilit√© r√©duite...\", description=\"\")\n",
    "\n",
    "# Affichage des questions\n",
    "for i, (label, widget) in enumerate([\n",
    "    (\"Quel type de destination pr√©f√®res-tu ?\", destination),\n",
    "    (\"Quel est ton budget approximatif ?\", budget),\n",
    "    (\"√Ä quelles dates veux-tu partir ?\", dates),\n",
    "    (\"Quelles activit√©s t‚Äôint√©ressent ?\", interets),\n",
    "    (\"Quel type d‚Äôh√©bergement pr√©f√®res-tu ?\", hebergement),\n",
    "    (\"Avec qui voyages-tu ?\", compagnie),\n",
    "    (\"As-tu des contraintes particuli√®res ?\", contraintes),\n",
    "]):\n",
    "    display(Markdown(f\"**{i+1}. {label}**\"))\n",
    "    display(widget)\n",
    "\n",
    "# Bouton de validation\n",
    "bouton = widgets.Button(description=\"‚ú® G√©n√©rer ma recommandation ‚úàÔ∏è\")\n",
    "\n",
    "# Zone pour le chat + widgets\n",
    "zone_chat = widgets.Output()\n",
    "zone_input = widgets.Textarea(placeholder=\"Pose une autre question, ou r√©agis √† la r√©ponse‚Ä¶\", layout=widgets.Layout(width='100%', height='60px'))\n",
    "bouton_suivant = widgets.Button(description=\"Envoyer üí¨\")\n",
    "\n",
    "# Fonction de r√©ponse continue\n",
    "def continuer_conversation(b):\n",
    "    user_input = zone_input.value.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "\n",
    "    zone_input.value = \"\"\n",
    "    with zone_chat:\n",
    "        display(Markdown(f\"**üë§ Toi :** {user_input}\"))\n",
    "\n",
    "    historique_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-tiny\",\n",
    "        \"messages\": historique_messages,\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_tokens\": 700\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = httpx.post(url, headers=headers, data=json.dumps(payload), timeout=30)\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        historique_messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        with zone_chat:\n",
    "            display(Markdown(f\"**ü§ñ Assistant :** {content}\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        with zone_chat:\n",
    "            display(Markdown(\"‚ùå **Erreur lors de l'appel √† Mistral.**\"))\n",
    "            print(e)\n",
    "\n",
    "# Associer la suite\n",
    "bouton_suivant.on_click(continuer_conversation)\n",
    "\n",
    "# Fonction d‚Äôappel initial\n",
    "def on_button_clicked(b):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(\"### ‚úàÔ∏è G√©n√©ration de ta recommandation...\"))\n",
    "\n",
    "    profil = f\"\"\"\n",
    "    Type de destination : {destination.value}\n",
    "    Budget : {budget.value}\n",
    "    Dates : {dates.value}\n",
    "    Centres d‚Äôint√©r√™t : {interets.value}\n",
    "    H√©bergement souhait√© : {hebergement.value}\n",
    "    Compagnie : {compagnie.value}\n",
    "    Contraintes : {contraintes.value}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Voici un profil utilisateur :\n",
    "{profil}\n",
    "\n",
    "Tu dois recommander :\n",
    "- une destination\n",
    "- un itin√©raire (si possible)\n",
    "- 2 ou 3 activit√©s principales\n",
    "- des suggestions d‚Äôh√©bergement\n",
    "- une justification de tes choix\n",
    "- des options alternatives (budget/premium) si pertinent\n",
    "\n",
    "R√©ponds en fran√ßais.\n",
    "\"\"\"\n",
    "\n",
    "    historique_messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-tiny\",\n",
    "        \"messages\": historique_messages,\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_tokens\": 700\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = httpx.post(url, headers=headers, data=json.dumps(payload), timeout=30)\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        historique_messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        display(Markdown(\"### ‚úÖ Recommandation g√©n√©r√©e :\"))\n",
    "        display(Markdown(f\"```\\n{content}\\n```\"))\n",
    "\n",
    "        # Afficher la suite : chat\n",
    "        display(Markdown(\"---\"))\n",
    "        display(Markdown(\"### üí¨ Tu peux continuer la discussion :\"))\n",
    "        display(zone_chat)\n",
    "        display(zone_input)\n",
    "        display(bouton_suivant)\n",
    "\n",
    "    except Exception as e:\n",
    "        display(Markdown(\"‚ùå **Erreur lors de l'appel √† Mistral :**\"))\n",
    "        print(e)\n",
    "\n",
    "# Attacher au bouton\n",
    "bouton.on_click(on_button_clicked)\n",
    "display(bouton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTIE NON GUIDEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Mistral (compar√© √† Ollama avec le m√™me prompt) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üí¨ Assistant Mistral ‚Äì Chat en direct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3ce6c34cf640bfbcf644e599a0b753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7046bea1e3477aaa43cda6daaf6b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='80px', width='100%'), placeholder='Pose une question ou continue la c‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cf5504c72d41ffab3a06ba46645fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Envoyer üí¨', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# üîê Charger la cl√© API\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "# üîó Configuration API\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# üß† Historique conversationnel\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant expert en voyages. Pose des questions si n√©cessaire, et fais des suggestions claires et adapt√©es.\"}\n",
    "]\n",
    "\n",
    "# üß± Interface utilisateur\n",
    "chat_box = widgets.Output()\n",
    "user_input = widgets.Textarea(\n",
    "    placeholder=\"Pose une question ou continue la conversation...\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"80px\")\n",
    ")\n",
    "send_button = widgets.Button(description=\"Envoyer üí¨\", button_style=\"primary\")\n",
    "\n",
    "# üì§ Fonction d‚Äôenvoi\n",
    "def envoyer_message(b):\n",
    "    prompt = user_input.value.strip()\n",
    "    if not prompt:\n",
    "        return\n",
    "\n",
    "    user_input.value = \"\"  # R√©initialiser l'input\n",
    "    conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with chat_box:\n",
    "        display(Markdown(f\"**üë§ Toi :** {prompt}\"))\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-tiny\",  # Ou mistral-small si dispo\n",
    "        \"messages\": conversation[-10:],  # limiter le contexte si besoin\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 600\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with chat_box:\n",
    "            print(\"‚è≥ Mistral r√©fl√©chit...\")\n",
    "\n",
    "        response = httpx.post(url, headers=headers, data=json.dumps(payload), timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        with chat_box:\n",
    "            clear_output(wait=True)\n",
    "            for msg in conversation[1:]:  # on saute le system\n",
    "                role = \"üë§ Toi\" if msg[\"role\"] == \"user\" else \"ü§ñ Mistral\"\n",
    "                display(Markdown(f\"**{role} :** {msg['content']}\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        with chat_box:\n",
    "            display(Markdown(f\"‚ùå **Erreur :** {e}\"))\n",
    "\n",
    "# üîÅ Lier le bouton √† la fonction\n",
    "send_button.on_click(envoyer_message)\n",
    "\n",
    "# üìã Affichage complet\n",
    "display(Markdown(\"## üí¨ Assistant Mistral ‚Äì Chat en direct\"))\n",
    "display(chat_box)\n",
    "display(user_input)\n",
    "display(send_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
